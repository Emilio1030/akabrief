{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat With Anything - From PDFs Files to Image Documents: \n",
    "Author: Zoumana KEITA   \n",
    "https://medium.com/@zoumanakeita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start due to the missing module 'IPython'. Consider installing this module.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresMissingModule'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install the requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RRYSu48huSUW",
    "outputId": "6374b7c8-9afc-4999-a31d-c9e980ee8a02"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "pip -q install langchain faiss-cpu unstructured\n",
    "pip -q install openai tiktoken\n",
    "pip -q install pytesseract pypdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pX3ndyD8E9hN"
   },
   "source": [
    "# Chat & Query your PDF files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect Document Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from filetype import guess\n",
    "\n",
    "def detect_document_type(document_path):\n",
    "\n",
    "    guess_file = guess(document_path)\n",
    "    file_type = \"\"\n",
    "    image_types = ['jpg', 'jpeg', 'png', 'gif']\n",
    "\n",
    "    if(guess_file.extension.lower() == \"pdf\"):\n",
    "        #print(guess_file.extension.lower())\n",
    "        file_type = \"pdf\"\n",
    "\n",
    "    elif(guess_file.extension.lower() in image_types):\n",
    "\n",
    "        file_type = \"image\"\n",
    "\n",
    "    else:\n",
    "        file_type = \"unkown\"\n",
    "\n",
    "    return file_type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess(\"1148_Notas_2023.pdf\").extension.lower() == \"image\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_paper_path = \"Banco BPI RC 2023port.pdf\"\n",
    "article_information_path = \"1148_Notas_2023.pdf\"\n",
    "\n",
    "print(f\"Research Paper Type: {detect_document_type(research_paper_path)}\")\n",
    "print(f\"Article Information Document Type: {detect_document_type(article_information_path)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Documents Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install unstructured rank_bm25 pdf2image pdfminer-six pikepdf pypdf unstructured_inference fastapi kaleido uvicorn \"pillow<10.1.0\" pillow_heif -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.partition.pdf import partition_pdf\n",
    "from unstructured.partition.image import partition_image\n",
    "from langchain.document_loaders.image import UnstructuredImageLoader\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "\n",
    "\"\"\"\n",
    "YOU CAN UNCOMMENT THE CODE BELOW TO UNDERSTAND THE LOGIC OF THE FUNCTIONS\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "\n",
    "def extract_text_from_pdf(pdf_file):\n",
    "\n",
    "    loader = UnstructuredFileLoader(pdf_file)\n",
    "    documents = loader.load()\n",
    "    pdf_pages_content = '\\n'.join(doc.page_content for doc in documents)\n",
    "\n",
    "    return pdf_pages_content\n",
    "b\n",
    "def extract_text_from_image(image_file):\n",
    "\n",
    "    loader = UnstructuredImageLoader(image_file)\n",
    "    documents = loader.load()\n",
    "\n",
    "    image_content = '\\n'.join(doc.page_content for doc in documents)\n",
    "\n",
    "    return image_content\n",
    "\"\"\"\n",
    "\n",
    "def extract_file_content(file_path):\n",
    "\n",
    "    file_type = detect_document_type(file_path)\n",
    "\n",
    "    if(file_type == \"pdf\"):\n",
    "        loader = UnstructuredFileLoader(file_path, mode=\"elements\")\n",
    "\n",
    "    elif(file_type == \"image\"):\n",
    "        loader = UnstructuredImageLoader(file_path)\n",
    "\n",
    "    documents = loader.load()\n",
    "    documents_content = '\\n'.join(doc.page_content for doc in documents)\n",
    "\n",
    "    return documents_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install other dependencies\n",
    "# https://github.com/Unstructured-IO/unstructured/blob/main/docs/source/installing.rst\n",
    "!brew install libmagic\n",
    "!brew install poppler\n",
    "!brew install tesseract\n",
    "# If parsing xml / html documents:\n",
    "!brew install libxml2\n",
    "!brew install libxslt\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredFileLoader\n",
    "\n",
    "loader = UnstructuredFileLoader(\"1148_Notas_2023.pdf\",  mode=\"elements\")\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#research_paper_content = extract_text_from_pdf(research_paper_path)\n",
    "#article_information_content = extract_text_from_image(article_information_path)\n",
    "\n",
    "\n",
    "#research_paper_content = extract_file_content(research_paper_path)\n",
    "article_information_content = extract_file_content(article_information_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_characters = 3000\n",
    "\n",
    "#print(f\"First {nb_characters} Characters of the Paper: \\n{research_paper_content[:nb_characters]}...\")\n",
    "#print(\"---\"*5)\n",
    "print(f\"First Characters of Article Information Document :\\n {article_information_content}...\")\n",
    "#article_information_content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator = \"\\n\\n\",\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap  = 200,\n",
    "    length_function = len,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "research_paper_chunks = text_splitter.split_text(research_paper_content)\n",
    "article_information_chunks = text_splitter.split_text(article_information_content)\n",
    "\n",
    "print(f\"# Chunks in Research Paper: {len(research_paper_chunks)}\")\n",
    "print(f\"# Chunks in Article Document: {len(article_information_chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<YOUR KEY>\"\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Vector Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "def get_doc_search(text_splitter):\n",
    "\n",
    "    return FAISS.from_texts(text_splitter, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_search_paper = get_doc_search(research_paper_chunks)\n",
    "print(doc_search_paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start chatting with your document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dNA4TsHpu6OM"
   },
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "chain = load_qa_chain(OpenAI(), chain_type = \"map_rerank\",\n",
    "                      return_intermediate_steps=True)\n",
    "\n",
    "def chat_with_file(file_path, query):\n",
    "\n",
    "    file_content = extract_file_content(file_path)\n",
    "    file_splitter = text_splitter.split_text(file_content)\n",
    "\n",
    "    document_search = get_doc_search(file_splitter)\n",
    "    documents = document_search.similarity_search(query)\n",
    "\n",
    "    results = chain({\n",
    "                        \"input_documents\":documents,\n",
    "                        \"question\": query\n",
    "                    },\n",
    "                    return_only_outputs=True)\n",
    "    results = results['intermediate_steps'][0]\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Chat with the image file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the document about\"\n",
    "\n",
    "results = chat_with_file(article_information_path, query)\n",
    "\n",
    "answer = results[\"answer\"]\n",
    "confidence_score = results[\"score\"]\n",
    "\n",
    "print(f\"Answer: {answer}\\n\\nConfidence Score: {confidence_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Chat with the PDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Why is the self-attention approach used in this document?\"\n",
    "\n",
    "results = chat_with_file(research_paper_path, query)\n",
    "\n",
    "answer = results[\"answer\"]\n",
    "confidence_score = results[\"score\"]\n",
    "\n",
    "print(f\"Answer: {answer}\\n\\nConfidence Score: {confidence_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!  \n",
    "\n",
    "Made with ❤️ by Zoumana KEITA"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "akasum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
